{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import joblib\n",
    "import random\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from dateutil import parser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reuters_Crawler(threading.Thread):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query: str\n",
    "        \n",
    "    Example:\n",
    "        RC = Reuters_Crawler()\n",
    "        df = RC.parse_to_dataframe()\n",
    "    \"\"\"\n",
    "    def __init__(self, queue, semaphore, query):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.semaphore = semaphore\n",
    "        self.query = query\n",
    "        self.driver_path = r\"./chromedriver.exe\"\n",
    "        self.next_button = '//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[4]/div[1]'\n",
    "    \n",
    "    def run(self):\n",
    "        self.semaphore.acquire()\n",
    "        self.parse_to_dataframe()\n",
    "        self.semaphore.release()\n",
    "    \n",
    "    def parse_to_dataframe(self):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            query: str\n",
    "        \"\"\"\n",
    "        # Open driver\n",
    "        self.url = \"https://www.reuters.com/search/news?blob={}&dateRange=all\".format(self.query)\n",
    "        self.driver = webdriver.Chrome(self.driver_path)\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(2)\n",
    "        # Scroll down page\n",
    "        self.scroll_to_bottom()\n",
    "        # Parsing\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        self.driver.quit()\n",
    "        news_list = soup.find_all(name=\"div\", attrs={\"class\": \"search-result-content\"})\n",
    "        news_list_generator = self.get_news_list(news_list)\n",
    "        df = pd.DataFrame(list(news_list_generator), columns=[\"title\", \"date\", \"query\", \"url\"])\n",
    "        joblib.dump(df, \"./data/reuters_news_{}_v1.joblib\".format(self.query.lower()), compress=3)\n",
    "                \n",
    "    def check_exists_by_xpath(self, xpath):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(xpath)\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def scroll_to_bottom(self):\n",
    "\n",
    "        old_position = 0\n",
    "        new_position = None\n",
    "\n",
    "        while new_position != old_position:\n",
    "            # Get old scroll position\n",
    "            old_position = self.driver.execute_script(\n",
    "                    (\"return (window.pageYOffset !== undefined) ?\"\n",
    "                     \" window.pageYOffset : (document.documentElement ||\"\n",
    "                     \" document.body.parentNode || document.body);\"))\n",
    "            \n",
    "            # Sleep and Scroll\n",
    "            time.sleep(3 + random.random())\n",
    "            self.driver.execute_script((\n",
    "                    \"var scrollingElement = (document.scrollingElement ||\"\n",
    "                    \" document.body);scrollingElement.scrollTop =\"\n",
    "                    \" scrollingElement.scrollHeight;\"))\n",
    "            \n",
    "            button = self.driver.find_element_by_xpath(self.next_button)\n",
    "            try:\n",
    "                self.driver.execute_script(\"arguments[0].click()\", button)\n",
    "            except WebDriverException as error:\n",
    "                print('Click failed...')\n",
    "                print(error)\n",
    "            # self.driver.execute_script(\"arguments[0].click()\", button)\n",
    "            time.sleep(3 + random.random())\n",
    "            \n",
    "            # Get new position\n",
    "            new_position = self.driver.execute_script(\n",
    "                    (\"return (window.pageYOffset !== undefined) ?\"\n",
    "                     \" window.pageYOffset : (document.documentElement ||\"\n",
    "                     \" document.body.parentNode || document.body);\"))\n",
    "    \n",
    "    def get_news_list(self, news_list):\n",
    "        for i in range(len(news_list)):\n",
    "            title = news_list[i].find(name=\"a\").text\n",
    "            date = news_list[i].find(name=\"h5\", attrs={\"class\": \"search-result-timestamp\"}).text\n",
    "            date = parser.parse(date, tzinfos={\"EDT\": \"UTC-8\", \"EST\": \"UTC-8\"})\n",
    "            url = news_list[i].find(name=\"a\").get(\"href\")\n",
    "            url = \"https://www.reuters.com\" + url\n",
    "            yield [title, date, self.query, url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"Microsoft\", \"Apple\"]\n",
    "paper_df = pd.DataFrame()\n",
    "\n",
    "semaphore = threading.Semaphore(2)\n",
    "threads = []\n",
    "my_queue = queue.Queue()\n",
    "\n",
    "for subject in subjects:\n",
    "    threads.append(Reuters_Crawler(my_queue, semaphore, subject))\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft to adapt its cloud software for heal...</td>\n",
       "      <td>2020-05-19 11:00:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSL1N2D100I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft to invest $1.5 bln in Italian cloud ...</td>\n",
       "      <td>2020-05-08 10:29:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSL8N2CQ4PU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft to adapt its cloud software for heal...</td>\n",
       "      <td>2020-05-19 11:29:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN22V27Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft to invest $1 bln in Poland - statement</td>\n",
       "      <td>2020-05-05 04:46:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSW8N2AY00G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft to invest $1 billion in Polish cloud...</td>\n",
       "      <td>2020-05-05 05:19:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN22H0WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Why Nokia didn't sell its patents to Microsoft</td>\n",
       "      <td>2013-09-03 19:05:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSBRE9820ZZ2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Microsoft needs Minecraft to boost mobile ambi...</td>\n",
       "      <td>2014-09-12 16:48:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN0H72EV2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Microsoft revamps Hotmail as social-friendly O...</td>\n",
       "      <td>2012-07-31 19:36:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSBRE86U10Z2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Microsoft hires ex-FTC Google expert as lobbyist</td>\n",
       "      <td>2012-03-01 19:09:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSTRE82100B2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Microsoft, Google tangle over Windows security...</td>\n",
       "      <td>2015-01-12 14:12:00-08:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN0KL20I2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Microsoft to adapt its cloud software for heal...   \n",
       "1    Microsoft to invest $1.5 bln in Italian cloud ...   \n",
       "2    Microsoft to adapt its cloud software for heal...   \n",
       "3     Microsoft to invest $1 bln in Poland - statement   \n",
       "4    Microsoft to invest $1 billion in Polish cloud...   \n",
       "..                                                 ...   \n",
       "905     Why Nokia didn't sell its patents to Microsoft   \n",
       "906  Microsoft needs Minecraft to boost mobile ambi...   \n",
       "907  Microsoft revamps Hotmail as social-friendly O...   \n",
       "908   Microsoft hires ex-FTC Google expert as lobbyist   \n",
       "909  Microsoft, Google tangle over Windows security...   \n",
       "\n",
       "                         date      query  \\\n",
       "0   2020-05-19 11:00:00-08:00  Microsoft   \n",
       "1   2020-05-08 10:29:00-08:00  Microsoft   \n",
       "2   2020-05-19 11:29:00-08:00  Microsoft   \n",
       "3   2020-05-05 04:46:00-08:00  Microsoft   \n",
       "4   2020-05-05 05:19:00-08:00  Microsoft   \n",
       "..                        ...        ...   \n",
       "905 2013-09-03 19:05:00-08:00  Microsoft   \n",
       "906 2014-09-12 16:48:00-08:00  Microsoft   \n",
       "907 2012-07-31 19:36:00-08:00  Microsoft   \n",
       "908 2012-03-01 19:09:00-08:00  Microsoft   \n",
       "909 2015-01-12 14:12:00-08:00  Microsoft   \n",
       "\n",
       "                                                   url  \n",
       "0        https://www.reuters.com/article/idUSL1N2D100I  \n",
       "1        https://www.reuters.com/article/idUSL8N2CQ4PU  \n",
       "2        https://www.reuters.com/article/idUSKBN22V27Z  \n",
       "3        https://www.reuters.com/article/idUSW8N2AY00G  \n",
       "4        https://www.reuters.com/article/idUSKBN22H0WP  \n",
       "..                                                 ...  \n",
       "905  https://www.reuters.com/article/idUSBRE9820ZZ2...  \n",
       "906  https://www.reuters.com/article/idUSKBN0H72EV2...  \n",
       "907  https://www.reuters.com/article/idUSBRE86U10Z2...  \n",
       "908  https://www.reuters.com/article/idUSTRE82100B2...  \n",
       "909  https://www.reuters.com/article/idUSKBN0KL20I2...  \n",
       "\n",
       "[910 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = joblib.load(\"../data/news/reuters_news_microsoft_v1.joblib\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SP500():\n",
    "    \"\"\"\n",
    "    There are 505 symbols due to several companies with two share classes. For example, \n",
    "    Google's parent company Alphabet has Class A (GOOGL) and Class C (GOOG) shares in the index.\n",
    "    When companies are removed and added to the index the membership list may temporarily show \n",
    "    both the removed company and added company.\n",
    "    \"\"\"\n",
    "    url = \"https://www.slickcharts.com/sp500\"\n",
    "    res = requests.get(url, timeout=10).text\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "    tbody = soup.find(name=\"tbody\")\n",
    "    for tr in tbody.find_all(name=\"tr\"):\n",
    "        company = tr.find_all(name=\"td\")[1].find_all(text=True)\n",
    "        company = \"\".join(company)\n",
    "        symbol = tr.find_all(name=\"td\")[2].find_all(text=True)\n",
    "        symbol = \"\".join(symbol)\n",
    "        weight = tr.find_all(name=\"td\")[3].find_all(text=True)\n",
    "        weight = \"\".join(weight)\n",
    "        yield [company, symbol, weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
