{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# An advanced Twitter scraping & OSINT tool written in Python that doesn't use Twitter's API.\n",
    "import twint\n",
    "\n",
    "# Solve compatibility issues with notebooks and RunTime errors.\n",
    "import warnings\n",
    "import nest_asyncio\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"twint/\")\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python preprocessing library.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable             Type       Description\n",
    "# Username             (string) - Twitter user's username\n",
    "# User_id              (string) - Twitter user's user_id\n",
    "# Search               (string) - Search terms\n",
    "# Geo                  (string) - Geo coordinates (lat,lon,km/mi.)\n",
    "# Location             (bool)   - Set to True to attempt to grab a Twitter user's location (slow).\n",
    "# Near                 (string) - Near a certain City (Example: london)\n",
    "# Lang                 (string) - Compatible language codes: https://github.com/twintproject/twint/wiki/Langauge-codes\n",
    "# Output               (string) - Name of the output file.\n",
    "# Elasticsearch        (string) - Elasticsearch instance\n",
    "# Timedelta            (int)    - Time interval for every request (days)\n",
    "# Year                 (string) - Filter Tweets before the specified year.\n",
    "# Since                (string) - Filter Tweets sent since date (Example: 2017-12-27).\n",
    "# Until                (string) - Filter Tweets sent until date (Example: 2017-12-27).\n",
    "# Email                (bool)   - Set to True to show Tweets that _might_ contain emails.\n",
    "# Phone                (bool)   - Set to True to show Tweets that _might_ contain phone numbers.\n",
    "# Verified             (bool)   - Set to True to only show Tweets by _verified_ users\n",
    "# Store_csv            (bool)   - Set to True to write as a csv file.\n",
    "# Store_json           (bool)   - Set to True to write as a json file.\n",
    "# Custom               (dict)   - Custom csv/json formatting (see below).\n",
    "# Show_hashtags        (bool)   - Set to True to show hashtags in the terminal output.\n",
    "# Limit                (int)    - Number of Tweets to pull (Increments of 20).\n",
    "# Count                (bool)   - Count the total number of Tweets fetched.\n",
    "# Stats                (bool)   - Set to True to show Tweet stats in the terminal output.\n",
    "# Database             (string) - Store Tweets in a sqlite3 database. Set this to the DB. (Example: twitter.db)\n",
    "# To                   (string) - Display Tweets tweeted _to_ the specified user.\n",
    "# All                  (string) - Display all Tweets associated with the mentioned user.\n",
    "# Debug                (bool)   - Store information in debug logs.\n",
    "# Format               (string) - Custom terminal output formatting.\n",
    "# Essid                (string) - Elasticsearch session ID.\n",
    "# User_full            (bool)   - Set to True to display full user information. By default, only usernames are shown.\n",
    "# Profile_full         (bool)   - Set to True to use a slow, but effective method to enumerate a user's Timeline.\n",
    "# Store_object         (bool)   - Store tweets/user infos/usernames in JSON objects.\n",
    "# Store_pandas         (bool)   - Save Tweets in a DataFrame (Pandas) file.\n",
    "# Pandas_type          (string) - Specify HDF5 or Pickle (HDF5 as default).\n",
    "# Pandas               (bool)   - Enable Pandas integration.\n",
    "# Index_tweets         (string) - Custom Elasticsearch Index name for Tweets (default: twinttweets).\n",
    "# Index_follow         (string) - Custom Elasticsearch Index name for Follows (default: twintgraph).\n",
    "# Index_users          (string) - Custom Elasticsearch Index name for Users (default: twintuser).\n",
    "# Index_type           (string) - Custom Elasticsearch Document type (default: items).\n",
    "# Retries_count        (int)    - Number of retries of requests (default: 10).\n",
    "# Resume               (int)    - Resume from a specific tweet id (**currently broken, January 11, 2019**).\n",
    "# Images               (bool)   - Display only Tweets with images.\n",
    "# Videos               (bool)   - Display only Tweets with videos.\n",
    "# Media                (bool)   - Display Tweets with only images or videos.\n",
    "# Replies              (bool)   - Display replies to a subject.\n",
    "# Pandas_clean         (bool)   - Automatically clean Pandas dataframe at every scrape.\n",
    "# Lowercase            (bool)   - Automatically convert uppercases in lowercases.\n",
    "# Pandas_au            (bool)   - Automatically update the Pandas dataframe at every scrape.\n",
    "# Proxy_host           (string) - Proxy hostname or IP.\n",
    "# Proxy_port           (int)    - Proxy port.\n",
    "# Proxy_type           (string) - Proxy type.\n",
    "# Tor_control_port     (int) - Tor control port.\n",
    "# Tor_control_password (string) - Tor control password (not hashed).\n",
    "# Retweets             (bool)   - Display replies to a subject.\n",
    "# Hide_output          (bool)   - Hide output.\n",
    "# Get_replies          (bool)   - All replies to the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "# 63 Top Forex Twitter Accounts: \n",
    "# https://www.forexcrunch.com/60-top-forex-twitter-accounts/\n",
    "# https://towardsdatascience.com/analyzing-tweets-with-nlp-in-minutes-with-spark-optimus-and-twint-a0c96084995f\n",
    "def tweets_to_dateframe_by_year(search, output_file, year=\"2020\"):\n",
    "    # Configure\n",
    "    c = twint.Config()\n",
    "    c.Search = search\n",
    "    c.Year = year\n",
    "    c.Lang = \"en\"\n",
    "    c.Pandas = True\n",
    "    c.Store_csv = True\n",
    "    c.Format = \"Username: {username} |  Tweet: {tweet}\"\n",
    "    c.Output = output_file\n",
    "    c.Hide_output = True\n",
    "\n",
    "    # Run\n",
    "    with HiddenPrints():\n",
    "        print(twint.run.Search(c))\n",
    "    \n",
    "    return \"Done scraping tweets!\"\n",
    "\n",
    "def tweets_to_dateframe_by_interval(search, output_file, since, until):\n",
    "    # Configure\n",
    "    c = twint.Config()\n",
    "    c.Search = search\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Lang = \"en\"\n",
    "    c.Pandas = True\n",
    "    c.Store_csv = True\n",
    "    c.Format = \"Username: {username} |  Tweet: {tweet}\"\n",
    "    c.Output = output_file\n",
    "    c.Hide_output = True\n",
    "\n",
    "    # Run\n",
    "    with HiddenPrints():\n",
    "        print(twint.run.Search(c))\n",
    "    \n",
    "    return \"Done scraping tweets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# headers = {'user-agent': \n",
    "#            'Mozilla/5.0 (Macintosh Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}\n",
    "# url = \"https://www.forexcrunch.com/60-top-forex-twitter-accounts/\"\n",
    "# res = requests.get(url, headers=headers).text\n",
    "# soup = BeautifulSoup(res, \"html.parser\")\n",
    "# trader_account = []\n",
    "# table = soup.find(name=\"ol\")\n",
    "# for account in table.find_all(name=\"li\"):\n",
    "#     name = account.find(name=\"a\").text\n",
    "#     name = name.replace(\"@\", \"\")\n",
    "#     trader_account.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Christine Lagarde: President of the European Central Bank\n",
    "# Jerome Powell: Chair of the Board of Governors of the Federal Reserve System\n",
    "# Mark Joseph Carney: Governor of the Bank of England\n",
    "# Haruhiko Kuroda: President of the Bank of Japan\n",
    "# Philip Lowe: President of the Reserve Bank of Australia\n",
    "# Adrian Orr: President of New Zealand's central bank\n",
    "# Zhou Xiaochuan: President of the People's Bank of China"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twint Proxies Issues (Not Solved)\n",
    "Twitter is blocking your IP for a fixed period of time (about 7 mins) after scraping a large batch of tweets. This progressive backoff is the best work around we've found so far. You'll just have to suck it up unless you can rotate your IP each time you get blocked.\n",
    "\n",
    "Reference from [here](https://github.com/twintproject/twint/issues/604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for account in tqdm(trader_account):\n",
    "#     tweets_to_dateframe_by_interval(\n",
    "#         search=account, \n",
    "#         output_file=\"../data/forex.csv\", \n",
    "#         since=\"2016-04-01\", \n",
    "#         until=\"2016-05-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in tqdm([\"2019\", \"2020\"]):\n",
    "#     for account in [\"Christine Lagarde\", \"Jerome Powell\", \"Mark Joseph Carney\", \n",
    "#                     \"Haruhiko Kuroda\", \"Philip Lowe\", \"Adrian Orr\", \"Zhou Xiaochuan\"]:\n",
    "#         tweets_to_dateframe_by_year(\n",
    "#            search=account, \n",
    "#            output_file=\"../data/forex.csv\", \n",
    "#            year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tweets: 1444416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-03-27</td>\n",
       "      <td>16:37:26</td>\n",
       "      <td>ioverlord</td>\n",
       "      <td>Director-General of DG Competition Philip Lowe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-03-27</td>\n",
       "      <td>16:37:26</td>\n",
       "      <td>ioverlord</td>\n",
       "      <td>Director-General of DG Competition Philip Lowe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-02-08</td>\n",
       "      <td>17:36:13</td>\n",
       "      <td>cnafrontpage</td>\n",
       "      <td>ADB chief says Asia not 'immune' to US slowdow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-02-08</td>\n",
       "      <td>17:36:13</td>\n",
       "      <td>cnafrontpage</td>\n",
       "      <td>ADB chief says Asia not 'immune' to US slowdow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-05-06</td>\n",
       "      <td>16:12:09</td>\n",
       "      <td>philiplowe</td>\n",
       "      <td>Trying to re-build my blog and my site</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time      username  \\\n",
       "0  2007-03-27  16:37:26     ioverlord   \n",
       "1  2007-03-27  16:37:26     ioverlord   \n",
       "2  2008-02-08  17:36:13  cnafrontpage   \n",
       "3  2008-02-08  17:36:13  cnafrontpage   \n",
       "4  2008-05-06  16:12:09    philiplowe   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  Director-General of DG Competition Philip Lowe...              0   \n",
       "1  Director-General of DG Competition Philip Lowe...              0   \n",
       "2  ADB chief says Asia not 'immune' to US slowdow...              0   \n",
       "3  ADB chief says Asia not 'immune' to US slowdow...              0   \n",
       "4             Trying to re-build my blog and my site              0   \n",
       "\n",
       "   retweets_count  likes_count hashtags  \n",
       "0               0            0       []  \n",
       "1               0            0       []  \n",
       "2               0            0       []  \n",
       "3               0            0       []  \n",
       "4               0            0       []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/forex_tweet.csv\", \n",
    "                 usecols=[\"date\", \"time\", \"username\", \"tweet\", \"hashtags\", \"likes_count\", \"replies_count\", \"retweets_count\"])\n",
    "print(\"# of tweets: {}\".format(df.shape[0]))\n",
    "df.sort_values(by=\"date\", ascending=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
